{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d0c972-9283-4d9a-aa64-2bbb668530da",
   "metadata": {
    "id": "21d0c972-9283-4d9a-aa64-2bbb668530da",
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14jDd34tH3cn",
   "metadata": {
    "id": "14jDd34tH3cn"
   },
   "source": [
    "# PC setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nF9159Y1H6Ow",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28524,
     "status": "ok",
     "timestamp": 1686236066070,
     "user": {
      "displayName": "松井映",
      "userId": "11373140638388017477"
     },
     "user_tz": -540
    },
    "id": "nF9159Y1H6Ow",
    "outputId": "e686ef2d-21a9-4491-a8e0-ecf3999b87c4"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# !pip install -r requirements_uavUnet.txt\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      3\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# !pip install -r requirements_uavUnet.txt\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    gpu_properties = torch.cuda.get_device_properties(device)\n",
    "    gpu_memory_size = gpu_properties.total_memory / 1024 ** 3  # Convert bytes to gigabytes\n",
    "    print(f\"GPU Memory Size: {gpu_memory_size:.2f} GB\")\n",
    "else:\n",
    "    print(\"GPU is not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_a6UZOcWICyw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1408,
     "status": "ok",
     "timestamp": 1686236067474,
     "user": {
      "displayName": "松井映",
      "userId": "11373140638388017477"
     },
     "user_tz": -540
    },
    "id": "_a6UZOcWICyw",
    "outputId": "722ae50c-d138-4492-b1e9-b4e3e9af33eb"
   },
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/Forest/src/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ruzw__DLJzRv",
   "metadata": {
    "id": "Ruzw__DLJzRv"
   },
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "364cbbed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5810,
     "status": "ok",
     "timestamp": 1686236073281,
     "user": {
      "displayName": "松井映",
      "userId": "11373140638388017477"
     },
     "user_tz": -540
    },
    "id": "364cbbed",
    "outputId": "4f9f95c0-eda4-4b1d-b507-2c1496eca8bd",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory Size: 16.00 GB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os, glob, sys\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# print(f\"GPU Memory Usage: {get_gpu_memory_usage():.2f} GiB\\n\")\n",
    "# print(\"Allocated Tensors:\")\n",
    "# print_allocated_tensors()\n",
    "\n",
    "import segment_model_training\n",
    "import importlib\n",
    "importlib.reload(segment_model_training)\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from segment_model_training import calculate_statistics,LoadDataSet,get_train_transform\n",
    "from fpathutils import copyLocaliImages, get_mskPath\n",
    "# importlib.reload(argmentDataset)\n",
    "# importlib.reload(get_train_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AZ85YWZVJ-KT",
   "metadata": {
    "id": "AZ85YWZVJ-KT"
   },
   "source": [
    "# LoadDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d102f7e-685b-4c52-9a48-83affead9268",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1686229904396,
     "user": {
      "displayName": "松井映",
      "userId": "11373140638388017477"
     },
     "user_tz": -540
    },
    "id": "8d102f7e-685b-4c52-9a48-83affead9268",
    "outputId": "3f88b26c-8cfe-4e1f-c664-8707ef0fcde7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正規化ずみ平均値: (0.485, 0.456, 0.406)\n",
      "正規化ずみ標準偏差: (0.229, 0.224, 0.225)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "datasetName = \"Forest tsumura 2 50m P4Pv2\"\n",
    "treeType = \"cypress\"\n",
    "cropSize = 1024\n",
    "lapSize=512\n",
    "\n",
    "# orgDir = f\"03_datasetforModel\\\\{datasetName}_{treeType}\\\\org_crop4Corner_5120_3072_Size{cropSize}_lap{lapSize}\".replace(\"\\\\\",\"/\")\n",
    "orgDir = f\"C:\\\\datas\\\\uav_cnn_cypress\\\\test_org_crop4Corner_5120_3072_Size1024_lap512\"\n",
    "orgPaths = glob.glob(orgDir + \"/*.*\")\n",
    "\n",
    "len(orgPaths)\n",
    "\n",
    "# フォルダのパスを指定して統計量を計算\n",
    "# mean_values, std_deviation = calculate_statistics(orgDir)\n",
    "mean_values, std_deviation = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n",
    "print(\"正規化ずみ平均値:\", mean_values)\n",
    "print(\"正規化ずみ標準偏差:\", std_deviation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8a3306b-565f-4790-b639-69ea9ddf1978",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1686229911091,
     "user": {
      "displayName": "松井映",
      "userId": "11373140638388017477"
     },
     "user_tz": -540
    },
    "id": "a8a3306b-565f-4790-b639-69ea9ddf1978",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# calculate_statistics(orgPaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf78fe8d-6e54-49b8-89aa-1d8237259f14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1686230054430,
     "user": {
      "displayName": "松井映",
      "userId": "11373140638388017477"
     },
     "user_tz": -540
    },
    "id": "cf78fe8d-6e54-49b8-89aa-1d8237259f14",
    "outputId": "b3c4f6e7-52aa-40c2-ec53-144844dea8d2",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "orgDataset_count = len(glob.glob(orgDir + \"/*.*\"))\n",
    "\n",
    "rotate_270per90 = True\n",
    "flipMirror = True\n",
    "\n",
    "# orgDir = segment_model_training.argmentDataset(orgDir, rotate=rotate_270per90, flipMirror=True)\n",
    "# segment_model_training.main(\"cedar\",2)\n",
    "\n",
    "\n",
    "workDir = \"./04_trainingModel\"\n",
    "TRAIN_PATH = workDir + f'/{datasetName}_{treeType}/'\n",
    "os.makedirs(TRAIN_PATH, exist_ok=True)\n",
    "orgDataset_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "685a1000",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1686230091785,
     "user": {
      "displayName": "松井映",
      "userId": "11373140638388017477"
     },
     "user_tz": -540
    },
    "id": "685a1000",
    "outputId": "b7d2b7d7-93ba-47d9-a43b-32ec8f783c60",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 28\n",
      "C:\\datas\\uav_cnn_cypress\\test_org_crop4Corner_5120_3072_Size1024_lap512\n"
     ]
    }
   ],
   "source": [
    "\n",
    "orgPaths = glob.glob(orgDir + \"/*.*\")\n",
    "img = Image.open(orgPaths[0])\n",
    "mskPaths = [get_mskPath(orgPath) for orgPath in orgPaths]\n",
    "print(len(orgPaths),len(mskPaths))\n",
    "\n",
    "# orgDir = copyLocaliImages(orgDir, f\"C:\\\\datas\\\\uav_cnn_{treeType}\")\n",
    "# orgPaths = glob.glob(orgDir + \"/*.*\")\n",
    "\n",
    "\n",
    "print(orgDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aGXhR4euJbhw",
   "metadata": {
    "id": "aGXhR4euJbhw"
   },
   "source": [
    "# PSQL connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9287e41",
   "metadata": {
    "id": "c9287e41",
    "outputId": "5152cfa6-ac1e-47d7-ee00-03febc5bf1f4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import psql_connect\n",
    "# importlib.reload(psql_connect)\n",
    "\n",
    "# engine, conn, engineSQL = psql_connect.getPSQL(databaseName=\"cnn_segment\", port=\"5432\", ownerName=\"matsuilocal\")\n",
    "\n",
    "# psql_connect.createTB_UnetDatasetUAV()\n",
    "# psql_connect.createTB_UnetTrainingUAV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15d78b76",
   "metadata": {
    "id": "15d78b76",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sqlalchemy import create_engine, Table, Column, Integer, String, Float, MetaData\n",
    "# from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "# # Define the metadata and the table\n",
    "# metadata = MetaData()\n",
    "# unet_dataset_uav = Table('unet_dataset_uav', metadata,\n",
    "#                          Column('id', Integer, primary_key=True),\n",
    "#                          Column('datasetName', String),\n",
    "#                          Column('classType', String),\n",
    "#                          Column('width', Integer),\n",
    "#                          Column('height', Integer),\n",
    "#                          Column('lapSize', Integer),\n",
    "#                          Column('original_dataset_count', Integer),\n",
    "#                          Column('argment_rotate', String),\n",
    "#                          Column('argment_flipMirror', String),\n",
    "#                          Column('datasetDir', String),\n",
    "#                          Column('dataset_count', Integer),\n",
    "#                          Column('mean', String),\n",
    "#                          Column('std', String),\n",
    "#                      )\n",
    "# import ast\n",
    "\n",
    "# select_SQL = \"select * from unet_dataset_uav;\"\n",
    "\n",
    "# df_db = pd.read_sql(sql=select_SQL, con=engineSQL)\n",
    "# if not str(list(mean_values)) in list(df_db[\"mean\"]):\n",
    "# # mean_values_fromDB = ast.literal_eval(df_db.loc[0,\"mean\"])\n",
    "#     # Create a session\n",
    "#     Session = sessionmaker(bind=engine)\n",
    "#     session = Session()\n",
    "\n",
    "#     # Create a new row to insert\n",
    "#     new_row = unet_dataset_uav.insert().values(\n",
    "#         datasetName=datasetName,\n",
    "#         classType=treeType,\n",
    "#         width=img.width,\n",
    "#         height=img.height,\n",
    "#         lapSize=lapSize,\n",
    "#         original_dataset_count=orgDataset_count,\n",
    "#         argment_rotate=rotate_270per90,\n",
    "#         argment_flipMirror=flipMirror,\n",
    "#         datasetDir=orgDir,\n",
    "#         dataset_count=len(orgPaths),\n",
    "#         mean=str(list(mean_values)),\n",
    "#         std=str(list(std_deviation)),\n",
    "#     )\n",
    "#     print(new_row)\n",
    "\n",
    "#     try:\n",
    "#         # Execute the insert statement\n",
    "#         session.execute(new_row)\n",
    "\n",
    "#         # Commit the changes\n",
    "#         session.commit()\n",
    "\n",
    "#         # Close the session\n",
    "#         session.close()\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9a3bec0",
   "metadata": {
    "id": "e9a3bec0",
    "outputId": "b9aa082e-2ca1-48a3-db7a-d04826f878b6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# datasetID = int(df_db[\"id\"][0])\n",
    "\n",
    "\n",
    "# getDatasetParam_SQL = f\"select * from unet_dataset_uav where id={4};\"\n",
    "# df = pd.read_sql(getDatasetParam_SQL,engine)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f845130",
   "metadata": {
    "id": "7f845130",
    "outputId": "7f07edb0-3e9c-4039-868d-c5d9cf7ecff5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# orgDir = df[\"datasetDir\"].iloc[0]\n",
    "# orgDir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xTgSTSbfK_lU",
   "metadata": {
    "id": "xTgSTSbfK_lU"
   },
   "source": [
    "# Dataset define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "49a3905b-1ecb-4334-9932-d852a9a68417",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 470,
     "status": "ok",
     "timestamp": 1686231392877,
     "user": {
      "displayName": "松井映",
      "userId": "11373140638388017477"
     },
     "user_tz": -540
    },
    "id": "49a3905b-1ecb-4334-9932-d852a9a68417",
    "outputId": "ac4f74f4-c44b-4d60-a802-3afbe067f469",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory Size: 16.00 GB\n",
      "C:\\\\datas\\\\uav_cnn_cypress\\\\test_org_crop4Corner_5120_3072_Size1024_lap512\n",
      "images count\t 28\n",
      "(2, 1024, 1024)\n",
      "mask torch.Size([2, 1024, 1024, 1])\n",
      "torch.float32 torch.float32\n",
      "torch.Size([3, 1024, 1024]) tensor(1.) tensor(0.3769) tensor(0.)\n",
      "tensor([0.0000, 0.0039, 0.0078, 0.0118, 0.0157, 0.0196])\n",
      "torch.Size([2, 1024, 1024, 1]) tensor(1.) tensor(0.5000) tensor(0.)\n",
      "tensor([0., 1.])\n",
      "torch.Size([3, 1024, 1024]) tensor(1.) tensor(0.3769) tensor(0.)\n",
      "tensor([0.0000, 0.0039, 0.0078, 0.0118, 0.0157, 0.0196])\n",
      "torch.Size([2, 1024, 1024, 1]) tensor(1.) tensor(0.5000) tensor(0.)\n",
      "tensor([0., 1.])\n",
      "train count : 20\n",
      "valid count : 8\n"
     ]
    }
   ],
   "source": [
    "from segment_model_training import printArrayStatics\n",
    "\n",
    "import segment_model_training\n",
    "importlib.reload(segment_model_training)\n",
    "\n",
    "print(orgDir.replace(\"\\\\\",\"\\\\\\\\\"))\n",
    "train_dataset = segment_model_training.LoadDataSet(orgDir)\n",
    "# train_dataset = LoadDataSet(orgDir.replace(\"\\\\\",\"\\\\\\\\\")+\"\\\\\")\n",
    "print(\"images count\\t\",train_dataset.__len__())\n",
    "\n",
    "org, msk = train_dataset.__getitem__(4)\n",
    "print(org.dtype, msk.dtype)\n",
    "printArrayStatics(org)\n",
    "printArrayStatics(msk)\n",
    "\n",
    "segment_model_training.printArrayStatics(org)\n",
    "segment_model_training.printArrayStatics(msk)\n",
    "\n",
    "BATCHSIZE = 1\n",
    "\n",
    "#データ前処理\n",
    "split_ratio = 0.3\n",
    "train_size=int(np.round(train_dataset.__len__()*(1 - split_ratio),0))\n",
    "valid_size=int(np.round(train_dataset.__len__()*split_ratio,0))\n",
    "\n",
    "print(f\"train count : {(train_size)}\")\n",
    "print(f\"valid count : {(valid_size)}\")\n",
    "\n",
    "\n",
    "train_data, valid_data = random_split(train_dataset, [train_size, valid_size])\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCHSIZE, shuffle=True)\n",
    "val_loader = DataLoader(dataset=valid_data, batch_size=BATCHSIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26a36e5-f969-4e78-990e-e54757d99466",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c12L7EtELRG3",
   "metadata": {
    "id": "c12L7EtELRG3"
   },
   "source": [
    "# Models module Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6f944cfa-ac30-4f49-9e2c-e14b51e65c12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class-cypress_data28_batch1_epoch100_modelresnet34-imagenet\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 16.00 GiB total capacity; 15.10 GiB already allocated; 0 bytes free; 15.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(modelID)\n\u001b[0;32m     19\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minit_weights\u001b[39m(module):\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module, nn\u001b[38;5;241m.\u001b[39mConv2d) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module, nn\u001b[38;5;241m.\u001b[39mConvTranspose2d):\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;66;03m# 畳み込み層や転置畳み込み層の重みを初期化\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m-> 1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[1;31m[... skipping similar frames: Module._apply at line 797 (1 times)]\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    816\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    819\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 820\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    821\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m-> 1143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 16.00 GiB total capacity; 15.10 GiB already allocated; 0 bytes free; 15.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# !pip install segmentation_models_pytorch\n",
    "from torch import nn\n",
    "from unet_model import UNet, DiceBCELoss, save_ckp, load_ckp\n",
    "from pre_segmentation_model import UnetModel, calculate_iou, validateModel\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import pre_segmentation_model\n",
    "importlib.reload(pre_segmentation_model)\n",
    "\n",
    "\n",
    "encoder_name = \"resnet34\"\n",
    "encoder_weight = \"imagenet\"\n",
    "DEVICE = \"cuda\"\n",
    "num_epochs = 100\n",
    "\n",
    "model = pre_segmentation_model.UnetModel(encoder_name, encoder_weight, in_ch=3, outClass=2, decoder_channels=[256, 128, 64, 32, 16], activationName=\"sigmoid\")\n",
    "modelID = \"class-{}_data{}_batch{}_epoch{}_model{}\".format(treeType,train_dataset.__len__(), BATCHSIZE, num_epochs, encoder_name + \"-\" + encoder_weight)\n",
    "print(modelID)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "def init_weights(module):\n",
    "    if isinstance(module, nn.Conv2d) or isinstance(module, nn.ConvTranspose2d):\n",
    "        # 畳み込み層や転置畳み込み層の重みを初期化\n",
    "        nn.init.xavier_uniform_(module.weight.data)\n",
    "        if module.bias is not None:\n",
    "            nn.init.constant_(module.bias.data, 0)\n",
    "    elif isinstance(module, nn.BatchNorm2d):\n",
    "        # バッチ正規化層の重みを初期化\n",
    "        nn.init.constant_(module.weight.data, 1)\n",
    "        nn.init.constant_(module.bias.data, 0)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "# optimizer = torch.optim.Adam([dict(model.parameters(),lr = 1e-3))])\n",
    "optimizer = torch.optim.Adam([dict(params=model.parameters(), lr=1e-9)])\n",
    "# 損失関数を定義します。セグメンテーションタスクのためにCrossEntropyLossを使用します。\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# criterion = smp.utils.losses.DiceLoss()\n",
    "criterion = smp.utils.losses.BCEWithLogitsLoss()\n",
    "\n",
    "accuracy_metric = smp.utils.metrics.IoU(threshold=0.5)\n",
    "metrics = [accuracy_metric]\n",
    "# valid_loss_min = np.Inf\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "# CuDNNを使用したネットワークのベンチマークを有効にし、パフォーマンスを最適化します。\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "train_epoch = smp.utils.train.TrainEpoch(\n",
    "    model, \n",
    "    loss=criterion, \n",
    "    metrics=metrics, \n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "valid_epoch = smp.utils.train.ValidEpoch(\n",
    "    model, \n",
    "    loss=criterion, \n",
    "    metrics=metrics, \n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "\n",
    "# os.makedirs(workDir, exist_ok=True)\n",
    "\n",
    "# データローダー（train_loader, val_loaderなど）を定義した後、訓練ループを開始します。\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    for images, masks in train_loader:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        printArrayStatics(masks)\n",
    "        \n",
    "        # 前方計算を行います。\n",
    "        predicts = model(images)\n",
    "        \n",
    "        # print(predicts.shape, masks.shape)\n",
    "        # print(\"\\tPred,mask\",predicts.cpu().min(), predicts.cpu().max(), masks.cpu().min(), masks.cpu().max())\n",
    "        # predicts[predicts>=0.5] = 1.0\n",
    "\n",
    "        # 損失を計算します。\n",
    "        loss = criterion(predicts, masks)\n",
    "        batch_iou = metrics[0](predicts, masks)\n",
    "        print(\"Epoch\",epoch,\"\\tLoss\", loss.unique(),\"\\tIoU\",batch_iou.unique())\n",
    "        \n",
    "        # 勾配を初期化します。\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # バックプロパゲーションを行います。\n",
    "        loss.backward()\n",
    "\n",
    "        # オプティマイザを更新します。\n",
    "        optimizer.step()\n",
    "\n",
    "    # バリデーションデータでモデルのパフォーマンスを評価します。\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, masks in val_loader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            # 前方計算を行います。\n",
    "            predicts = model(images)\n",
    "            \n",
    "            # print(predicts.unique())\n",
    "            pred_show = predicts[0]\n",
    "            pred_show = (pred_show >= 0.5).float()\n",
    "            # print(pred_show.unique())\n",
    "            \n",
    "            segment_model_training.savePred(img_show=images[0],\n",
    "                                            msk_show=masks[0],\n",
    "                                            pred=pred_show,\n",
    "                                            # mean_values=mean_values,\n",
    "                                            # std_deviation=std_deviation,\n",
    "                                            mean_values=[0,0,0],\n",
    "                                            std_deviation=[0,0,0],\n",
    "                                            workDir=workDir,\n",
    "                                            epoch=epoch,\n",
    "                                            modelID=modelID)\n",
    "\n",
    "            pred_show = predicts[1]\n",
    "            pred_show = (pred_show >= 0.5).float()\n",
    "            # print(pred_show.unique())\n",
    "            \n",
    "            segment_model_training.savePred(img_show=images[1],\n",
    "                                            msk_show=masks[1],\n",
    "                                            pred=pred_show,\n",
    "                                            # mean_values=mean_values,\n",
    "                                            # std_deviation=std_deviation,\n",
    "                                            mean_values=[0,0,0],\n",
    "                                            std_deviation=[0,0,0],\n",
    "                                            workDir=workDir,\n",
    "                                            epoch=epoch,\n",
    "                                            modelID=modelID)\n",
    "            \n",
    "            # ここで必要なら評価指標を計算します。\n",
    "\n",
    "# モデルを保存します。\n",
    "torch.save(model.state_dict(),os.path.join(workDir,'mworkDirpth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9c4109a-c0f2-4d52-9c17-41671a746292",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1686231865558,
     "user": {
      "displayName": "松井映",
      "userId": "11373140638388017477"
     },
     "user_tz": -540
    },
    "id": "c9c4109a-c0f2-4d52-9c17-41671a746292",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./04_trainingModel\\class-cypress_data28_batch2_epoch100_modelresnet34-imagenet\\model_cypress_chkpoint_\n",
      "./04_trainingModel\\class-cypress_data28_batch2_epoch100_modelresnet34-imagenet\\model_cypress_bestmodel.pt\n",
      "GPU Memory Usage: 3.52 GiB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = os.path.join(workDir,f'model_{treeType}_chkpoint_')\n",
    "best_model_path = os.path.join(workDir,f'model_{treeType}_bestmodel.pt')\n",
    "os.makedirs(os.path.dirname(best_model_path), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "\n",
    "print(checkpoint_path)\n",
    "print(best_model_path)\n",
    "\n",
    "total_train_loss = []\n",
    "total_train_score = []\n",
    "total_valid_loss = []\n",
    "total_valid_score = []\n",
    "losses_value = 0\n",
    "\n",
    "\n",
    "def get_gpu_memory_usage():\n",
    "    \"\"\"GPUメモリの使用量を取得する関数\"\"\"\n",
    "    return torch.cuda.memory_allocated() / 1024**3  # GiB単位で返す\n",
    "\n",
    "def print_allocated_tensors():\n",
    "    \"\"\"GPUメモリを占有している変数の一覧を表示する関数\"\"\"\n",
    "    tensor_list = torch.cuda.memory_summary()  # 現在GPUメモリに割り当てられているテンソルの一覧を取得\n",
    "    print(tensor_list)\n",
    "\n",
    "# 使用例\n",
    "print(f\"GPU Memory Usage: {get_gpu_memory_usage():.2f} GiB\\n\")\n",
    "# print_allocated_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e65b66ab-4153-4e22-9904-1060ea1cb67e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 62385,
     "status": "ok",
     "timestamp": 1686232731161,
     "user": {
      "displayName": "松井映",
      "userId": "11373140638388017477"
     },
     "user_tz": -540
    },
    "id": "e65b66ab-4153-4e22-9904-1060ea1cb67e",
    "outputId": "895c2936-136e-4afb-a68e-e507adc3244b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.53it/s, bce_with_logits_loss - 0.8059, iou_score - 0.2431]\n",
      "valid: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.64it/s, bce_with_logits_loss - 0.8908, iou_score - 0.09547]\n",
      "{'bce_with_logits_loss': 0.8058724701404572, 'iou_score': 0.24309500306845738}\n",
      "{'bce_with_logits_loss': 0.890825092792511, 'iou_score': 0.09547429636592669}\n",
      "Model saved!\n",
      "Decrease decoder learning rate to 1e-5\n",
      "Epoch:2\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.62it/s, bce_with_logits_loss - 0.8025, iou_score - 0.2583]\n",
      "valid: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.24it/s, bce_with_logits_loss - 0.8686, iou_score - 0.118]\n",
      "{'bce_with_logits_loss': 0.8024658262729645, 'iou_score': 0.25825796164573256}\n",
      "{'bce_with_logits_loss': 0.8685535937547684, 'iou_score': 0.11801002954606246}\n",
      "Model saved!\n",
      "Epoch:3\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.60it/s, bce_with_logits_loss - 0.7972, iou_score - 0.2719]\n",
      "valid: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.42it/s, bce_with_logits_loss - 0.8571, iou_score - 0.1302]\n",
      "{'bce_with_logits_loss': 0.7972013831138611, 'iou_score': 0.27189943417908785}\n",
      "{'bce_with_logits_loss': 0.8571167886257172, 'iou_score': 0.13015204016127763}\n",
      "Model saved!\n",
      "Epoch:4\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.83it/s, bce_with_logits_loss - 0.7932, iou_score - 0.2876]\n",
      "valid: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.51it/s, bce_with_logits_loss - 0.8493, iou_score - 0.143]\n",
      "{'bce_with_logits_loss': 0.793170726299286, 'iou_score': 0.2875807380303841}\n",
      "{'bce_with_logits_loss': 0.8492854237556458, 'iou_score': 0.14295346790468055}\n",
      "Model saved!\n",
      "Epoch:5\n",
      "train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.49it/s, bce_with_logits_loss - 0.783, iou_score - 0.3603]\n",
      "valid: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.02it/s, bce_with_logits_loss - 0.8531, iou_score - 0.1541]\n",
      "{'bce_with_logits_loss': 0.7830384373664856, 'iou_score': 0.36025436669589106}\n",
      "{'bce_with_logits_loss': 0.8530661314725876, 'iou_score': 0.15409585286405666}\n",
      "Model saved!\n",
      "Epoch:6\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.72it/s, bce_with_logits_loss - 0.7775, iou_score - 0.3826]\n",
      "valid: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.23it/s, bce_with_logits_loss - 0.8488, iou_score - 0.1611]\n",
      "{'bce_with_logits_loss': 0.7775496542453766, 'iou_score': 0.38261330053211284}\n",
      "{'bce_with_logits_loss': 0.8487961441278458, 'iou_score': 0.16109949012761224}\n",
      "Model saved!\n",
      "Epoch:7\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.82it/s, bce_with_logits_loss - 0.7799, iou_score - 0.3452]\n",
      "valid: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.06it/s, bce_with_logits_loss - 0.8361, iou_score - 0.1692]\n",
      "{'bce_with_logits_loss': 0.7799053609371186, 'iou_score': 0.34523755479605023}\n",
      "{'bce_with_logits_loss': 0.836055263876915, 'iou_score': 0.16922281263406008}\n",
      "Model saved!\n",
      "Epoch:8\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.75it/s, bce_with_logits_loss - 0.7789, iou_score - 0.3442]\n",
      "valid: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.39it/s, bce_with_logits_loss - 0.8314, iou_score - 0.177]\n",
      "{'bce_with_logits_loss': 0.7788815498352051, 'iou_score': 0.34415097907185555}\n",
      "{'bce_with_logits_loss': 0.8314003795385361, 'iou_score': 0.17695016739899944}\n",
      "Model saved!\n",
      "Epoch:9\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.78it/s, bce_with_logits_loss - 0.7693, iou_score - 0.3798]\n",
      "valid: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.27it/s, bce_with_logits_loss - 0.8232, iou_score - 0.1866]\n",
      "{'bce_with_logits_loss': 0.7692645251750946, 'iou_score': 0.37979327291250226}\n",
      "{'bce_with_logits_loss': 0.823194682598114, 'iou_score': 0.186606785515435}\n",
      "Model saved!\n",
      "Epoch:10\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.74it/s, bce_with_logits_loss - 0.7591, iou_score - 0.4384]\n",
      "valid: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.47it/s, bce_with_logits_loss - 0.8071, iou_score - 0.1981]\n",
      "{'bce_with_logits_loss': 0.7591056525707245, 'iou_score': 0.4383652277290821}\n",
      "{'bce_with_logits_loss': 0.8071485757827759, 'iou_score': 0.198052229359884}\n",
      "Model saved!\n",
      "Epoch:11\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.80it/s, bce_with_logits_loss - 0.7633, iou_score - 0.3845]\n",
      "valid: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.13it/s, bce_with_logits_loss - 0.7906, iou_score - 0.2108]\n",
      "{'bce_with_logits_loss': 0.7633260965347289, 'iou_score': 0.3844812337309122}\n",
      "{'bce_with_logits_loss': 0.7905919849872589, 'iou_score': 0.2107623815538467}\n",
      "Model saved!\n",
      "Decrease decoder learning rate to 1e-5\n",
      "Epoch:12\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.73it/s, bce_with_logits_loss - 0.7592, iou_score - 0.3881]\n",
      "valid: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.35it/s, bce_with_logits_loss - 0.7641, iou_score - 0.2237]\n",
      "{'bce_with_logits_loss': 0.7591886639595031, 'iou_score': 0.3881384074688217}\n",
      "{'bce_with_logits_loss': 0.7640950977802277, 'iou_score': 0.22370650805577735}\n",
      "Model saved!\n",
      "Epoch:13\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.82it/s, bce_with_logits_loss - 0.7441, iou_score - 0.4862]\n",
      "valid: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.19it/s, bce_with_logits_loss - 0.7767, iou_score - 0.221]\n",
      "{'bce_with_logits_loss': 0.7441073417663574, 'iou_score': 0.48616432771086693}\n",
      "{'bce_with_logits_loss': 0.7766629457473755, 'iou_score': 0.2209670664745677}\n",
      "not improve for 1Epoch\n",
      "Epoch:14\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.69it/s, bce_with_logits_loss - 0.7413, iou_score - 0.4842]\n",
      "valid: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  7.80it/s, bce_with_logits_loss - 0.7739, iou_score - 0.2324]\n",
      "{'bce_with_logits_loss': 0.7412913799285888, 'iou_score': 0.4842359513044357}\n",
      "{'bce_with_logits_loss': 0.773937463760376, 'iou_score': 0.23240570537787225}\n",
      "Model saved!\n",
      "Epoch:15\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.81it/s, bce_with_logits_loss - 0.7358, iou_score - 0.5093]\n",
      "valid: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.23it/s, bce_with_logits_loss - 0.7513, iou_score - 0.2363]\n",
      "{'bce_with_logits_loss': 0.7358042418956756, 'iou_score': 0.5092627976089715}\n",
      "{'bce_with_logits_loss': 0.7513318359851837, 'iou_score': 0.23629091773262828}\n",
      "Model saved!\n",
      "Epoch:16\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.80it/s, bce_with_logits_loss - 0.7386, iou_score - 0.4865]\n",
      "valid: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.07it/s, bce_with_logits_loss - 0.7582, iou_score - 0.2396]\n",
      "{'bce_with_logits_loss': 0.7385739445686341, 'iou_score': 0.4864721145481004}\n",
      "{'bce_with_logits_loss': 0.758229523897171, 'iou_score': 0.23960637860061604}\n",
      "Model saved!\n",
      "Epoch:17\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.81it/s, bce_with_logits_loss - 0.7234, iou_score - 0.5859]\n",
      "valid: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.31it/s, bce_with_logits_loss - 0.7543, iou_score - 0.2377]\n",
      "{'bce_with_logits_loss': 0.7233903706073761, 'iou_score': 0.5859367273748046}\n",
      "{'bce_with_logits_loss': 0.7543291598558426, 'iou_score': 0.23772726021775736}\n",
      "not improve for 1Epoch\n",
      "Epoch:18\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.74it/s, bce_with_logits_loss - 0.7303, iou_score - 0.5082]\n",
      "valid: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  7.37it/s, bce_with_logits_loss - 0.7435, iou_score - 0.2576]\n",
      "{'bce_with_logits_loss': 0.7303122282028198, 'iou_score': 0.5082295060157777}\n",
      "{'bce_with_logits_loss': 0.7434827983379364, 'iou_score': 0.25762135163090777}\n",
      "Model saved!\n",
      "Epoch:19\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.72it/s, bce_with_logits_loss - 0.7273, iou_score - 0.5249]\n",
      "valid: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.04it/s, bce_with_logits_loss - 0.7303, iou_score - 0.2485]\n",
      "{'bce_with_logits_loss': 0.7273117005825043, 'iou_score': 0.5248770520091335}\n",
      "{'bce_with_logits_loss': 0.730336457490921, 'iou_score': 0.24850116111555934}\n",
      "not improve for 1Epoch\n",
      "Epoch:20\n",
      "train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.62it/s, bce_with_logits_loss - 0.727, iou_score - 0.5311]\n",
      "valid: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  7.99it/s, bce_with_logits_loss - 0.7658, iou_score - 0.2436]\n",
      "{'bce_with_logits_loss': 0.7270306408405304, 'iou_score': 0.5311104223132393}\n",
      "{'bce_with_logits_loss': 0.765849307179451, 'iou_score': 0.2435639603067175}\n",
      "not improve for 2Epoch\n",
      "Epoch:21\n",
      "train: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.72it/s, bce_with_logits_loss - 0.722, iou_score - 0.5451]\n",
      "valid: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.12it/s, bce_with_logits_loss - 0.736, iou_score - 0.2452]\n",
      "{'bce_with_logits_loss': 0.721987122297287, 'iou_score': 0.5450550235807896}\n",
      "{'bce_with_logits_loss': 0.7360042333602905, 'iou_score': 0.2451951075368559}\n",
      "not improve for 3Epoch\n",
      "Decrease decoder learning rate to 1e-5\n",
      "Epoch:22\n",
      "train: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.77it/s, bce_with_logits_loss - 0.72, iou_score - 0.5512]\n",
      "valid: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.39it/s, bce_with_logits_loss - 0.7522, iou_score - 0.2586]\n",
      "{'bce_with_logits_loss': 0.7199634552001953, 'iou_score': 0.5512053743005086}\n",
      "{'bce_with_logits_loss': 0.7521726042032242, 'iou_score': 0.25860410928851196}\n",
      "Model saved!\n",
      "Epoch:23\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.72it/s, bce_with_logits_loss - 0.7106, iou_score - 0.6231]\n",
      "valid: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  7.70it/s, bce_with_logits_loss - 0.7413, iou_score - 0.2454]\n",
      "{'bce_with_logits_loss': 0.710582810640335, 'iou_score': 0.6230567906052024}\n",
      "{'bce_with_logits_loss': 0.7413096129894257, 'iou_score': 0.24543131003218896}\n",
      "not improve for 1Epoch\n",
      "Epoch:24\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.80it/s, bce_with_logits_loss - 0.7494, iou_score - 0.3596]\n",
      "valid: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.49it/s, bce_with_logits_loss - 0.7519, iou_score - 0.2523]\n",
      "{'bce_with_logits_loss': 0.7493638694286346, 'iou_score': 0.3596004929393673}\n",
      "{'bce_with_logits_loss': 0.7519154101610184, 'iou_score': 0.2523051062603216}\n",
      "not improve for 2Epoch\n",
      "Epoch:25\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.83it/s, bce_with_logits_loss - 0.7049, iou_score - 0.6269]\n",
      "valid: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.39it/s, bce_with_logits_loss - 0.7215, iou_score - 0.2526]\n",
      "{'bce_with_logits_loss': 0.7048714518547058, 'iou_score': 0.6268881566822664}\n",
      "{'bce_with_logits_loss': 0.7215404957532883, 'iou_score': 0.2526373080928378}\n",
      "not improve for 3Epoch\n",
      "Epoch:26\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.74it/s, bce_with_logits_loss - 0.7158, iou_score - 0.5632]\n",
      "valid: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  7.64it/s, bce_with_logits_loss - 0.7578, iou_score - 0.2445]\n",
      "{'bce_with_logits_loss': 0.7157818794250488, 'iou_score': 0.5631576910615254}\n",
      "{'bce_with_logits_loss': 0.7577661871910095, 'iou_score': 0.24446853622827888}\n",
      "not improve for 4Epoch\n",
      "Epoch:27\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.68it/s, bce_with_logits_loss - 0.7117, iou_score - 0.5719]\n",
      "valid: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  8.64it/s, bce_with_logits_loss - 0.7197, iou_score - 0.2453]\n",
      "{'bce_with_logits_loss': 0.7116878569126128, 'iou_score': 0.5719227604568005}\n",
      "{'bce_with_logits_loss': 0.7196990549564362, 'iou_score': 0.24531060830505963}\n",
      "not improve for 5Epoch\n",
      "early stop. Max Score 0.25860410928851196\n"
     ]
    }
   ],
   "source": [
    "patience = 5 # 5Epcoch以上連続でモデル精度が向上しなければEarly Stopping\n",
    "early_stop_counter = 0\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "max_score = 0\n",
    "for i in range(num_epochs):\n",
    "    \n",
    "    print(f\"Epoch:{i+1}\")\n",
    "    train_logs = train_epoch.run(train_loader)\n",
    "    valid_logs = valid_epoch.run(val_loader)\n",
    "    \n",
    "    pprint(train_logs)\n",
    "    pprint(valid_logs)\n",
    "    \n",
    "    # IoUスコアが最高値が更新されればモデルを保存\n",
    "    if max_score < valid_logs[\"iou_score\"]:\n",
    "        max_score = valid_logs[\"iou_score\"]\n",
    "        torch.save(model, checkpoint_path)\n",
    "        print(\"Model saved!\")\n",
    "        early_stop_counter = 0\n",
    "\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        print(f\"not improve for {early_stop_counter}Epoch\")\n",
    "        if early_stop_counter==patience:\n",
    "            print(f\"early stop. Max Score {max_score}\")\n",
    "            break\n",
    "\n",
    "    # 適当なタイミングでlearning rateの変更\n",
    "    if i % 10==0:\n",
    "        optimizer.param_groups[0][\"lr\"] = 1e-5\n",
    "        print(\"Decrease decoder learning rate to 1e-5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76828a2d",
   "metadata": {
    "id": "76828a2d",
    "outputId": "89d1670a-4c5d-47b4-ecdb-37ca48372dcc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory Size: 16.00 GB\n",
      "0 org_test.unique() [0.         0.00416667 0.00833333 0.0125     0.01666667 0.02083333\n",
      " 0.025      0.02916667 0.03333334 0.0375     0.04166667 0.04583333\n",
      " 0.05       0.05416667 0.05833333 0.0625     0.06666667 0.07083333\n",
      " 0.075      0.07916667 0.08333334 0.0875     0.09166667 0.09583333\n",
      " 0.1        0.10416666 0.10833333 0.1125     0.11666667 0.12083333\n",
      " 0.125      0.12916666 0.13333334 0.1375     0.14166667 0.14583333\n",
      " 0.15       0.15416667 0.15833333 0.1625     0.16666667 0.17083333\n",
      " 0.175      0.17916666 0.18333334 0.1875     0.19166666 0.19583334\n",
      " 0.2        0.20416667]\n",
      "0 msk_show.unique() [0.]\n",
      "0 pred_sig.unique() [0.50011766 0.50017285 0.5003491  ... 0.7278361  0.7278646  0.72880834]\n",
      "predShape torch.Size([1024, 1024]) torch.float32\n",
      "torch.float32\n",
      "0 pred.unique() [0.50011766 0.50017285 0.5003491  ... 0.7278361  0.7278646  0.72880834]\n",
      "./04_trainingModel\\class-cypress_data28_batch2_epoch100_modelresnet34-imagenet\\\n",
      "class-cypress_data28_batch2_epoch100_modelresnet34-imagenet\n",
      "img_show.shape (1024, 1024, 3)\n",
      "msk_show.shape (1024, 1024)\n",
      "output.shape torch.Size([1024, 1024])\n",
      "pred.shape torch.Size([1024, 1024])\n",
      "pred.shape torch.Size([1024, 1024]) <class 'torch.Tensor'>\n",
      "1 pred.unique() [0.50011766 0.50017285 0.5003491  ... 0.7278361  0.7278646  0.72880834]\n",
      "pred_msk.unique() [0.50011766 0.50017285 0.5003491  ... 0.7278361  0.7278646  0.72880834] 774971\n",
      "pred.unique() [0.50011766 0.50017285 0.5003491  ... 0.7278361  0.7278646  0.72880834]\n",
      "org.unique() [0.         0.00416667 0.00833333 0.0125     0.01666667 0.02083333\n",
      " 0.025      0.02916667 0.03333334 0.0375    ]\n",
      "msk.unique() [0.]\n",
      "pred.unique() [0]\n",
      "img_show.shape (1024, 1024, 3)\n",
      "msk_show.shape (1024, 1024)\n",
      "torch.Size([3, 1024, 1024])\n"
     ]
    }
   ],
   "source": [
    "workDir = \"./04_trainingModel\"\n",
    "\n",
    "from segment_model_training import showPred\n",
    "importlib.reload(segment_model_training)\n",
    "\n",
    "\n",
    "\n",
    "workDir = os.path.join(workDir, modelID) + \"\\\\\"\n",
    "os.makedirs(workDir, exist_ok=True)\n",
    "\n",
    "img_show, msk_show = random.choice(valid_data)\n",
    "# img_show[img_show<=0]=0\n",
    "print(\"0 org_test.unique()\",np.unique(img_show)[:50]) \n",
    "print(\"0 msk_show.unique()\",np.unique(msk_show)) \n",
    "\n",
    "\n",
    "img_pred = torch.stack([org, org])\n",
    "# pred = model(img_show.cuda())\n",
    "pred = torch.sigmoid(model(img_pred.cuda()))\n",
    "print(\"0 pred_sig.unique()\",np.unique(pred.data.cpu())) \n",
    "pred = pred[0][0]\n",
    "print(\"predShape\",pred.shape,pred.data.cpu().dtype)\n",
    "print(msk_show.dtype)\n",
    "print(\"0 pred.unique()\",np.unique(pred.data.cpu())) \n",
    "img_show = img_show.cuda()\n",
    "\n",
    "print(workDir)\n",
    "print(modelID)\n",
    "segment_model_training.showPred(img_show=img_show, msk_show=msk_show, pred=pred,\n",
    "         mean_values=mean_values, std_deviation=std_deviation,\n",
    "         workDir=workDir, epoch=1, modelID=\"testmodel\",\n",
    "         imgSave=True)    \n",
    "print(org.shape)\n",
    "\n",
    "\n",
    "# pred = model(org)[0][0]\n",
    "# pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed66887",
   "metadata": {
    "id": "9ed66887",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = {'dataset_Mean': mean_values, 'dataset_Std Deviation': std_deviation}\n",
    "df_statics = pd.DataFrame(data)\n",
    "# DataFrameをCSVファイルとして保存\n",
    "df_statics.to_csv(workDir + f\"statistics_{modelID}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecdbb5d",
   "metadata": {
    "id": "1ecdbb5d",
    "outputId": "f8b67f63-3862-4aec-9a91-7513afca708f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pre_segmentation_model' from 'H:\\\\マイドライブ\\\\Forest\\\\src\\\\pre_segmentation_model.py'>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# del pre_segmentation_model\n",
    "import pre_segmentation_model\n",
    "importlib.reload(pre_segmentation_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f27b6e63-b850-4eda-89d6-723a03b55233",
   "metadata": {
    "id": "f27b6e63-b850-4eda-89d6-723a03b55233",
    "outputId": "23793ba4-6583-4e2e-f9b7-ebb9e75ecefb",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.9117\n",
      "Average IoU: 0.2905\n",
      "Train Loss: 0.9116533696651459, Train IOU: 0.2905269622802782\n",
      "Valid Loss: nan, Valid IOU: nan\n",
      "CheckPoint Save class-cypress_data28_batch2_epoch100_modelresnet34-imagenet\n",
      "\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.9117\n",
      "Average IoU: 0.2905\n",
      "Train Loss: 0.911653357744217, Train IOU: 0.2905269622802782\n",
      "Valid Loss: nan, Valid IOU: nan\n",
      "CheckPoint Save class-cypress_data28_batch2_epoch100_modelresnet34-imagenet\n",
      "\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.9117\n",
      "Average IoU: 0.2905\n",
      "Train Loss: 0.911653357744217, Train IOU: 0.2905269622802782\n",
      "Valid Loss: nan, Valid IOU: nan\n",
      "CheckPoint Save class-cypress_data28_batch2_epoch100_modelresnet34-imagenet\n",
      "\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.9117\n",
      "Average IoU: 0.2905\n",
      "Train Loss: 0.9116533935070038, Train IOU: 0.2905269622802782\n",
      "Valid Loss: nan, Valid IOU: nan\n",
      "CheckPoint Save class-cypress_data28_batch2_epoch100_modelresnet34-imagenet\n",
      "\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.9117\n",
      "Average IoU: 0.2905\n",
      "Train Loss: 0.9116533637046814, Train IOU: 0.29052696228028774\n",
      "Valid Loss: nan, Valid IOU: nan\n",
      "CheckPoint Save class-cypress_data28_batch2_epoch100_modelresnet34-imagenet\n",
      "\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.9117\n",
      "Average IoU: 0.2905\n",
      "Train Loss: 0.9116533458232879, Train IOU: 0.29052696228028296\n",
      "Valid Loss: nan, Valid IOU: nan\n",
      "CheckPoint Save class-cypress_data28_batch2_epoch100_modelresnet34-imagenet\n",
      "\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.9117\n",
      "Average IoU: 0.2905\n",
      "Train Loss: 0.9116533786058426, Train IOU: 0.29052696228028296\n",
      "Valid Loss: nan, Valid IOU: nan\n",
      "CheckPoint Save class-cypress_data28_batch2_epoch100_modelresnet34-imagenet\n",
      "\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.9117\n",
      "Average IoU: 0.2905\n",
      "Train Loss: 0.9116533517837524, Train IOU: 0.29052696228028296\n",
      "Valid Loss: nan, Valid IOU: nan\n",
      "CheckPoint Save class-cypress_data28_batch2_epoch100_modelresnet34-imagenet\n",
      "\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:06<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.9117\n",
      "Average IoU: 0.2905\n",
      "Train Loss: 0.9116533696651459, Train IOU: 0.29052696228028296\n",
      "Valid Loss: nan, Valid IOU: nan\n",
      "CheckPoint Save class-cypress_data28_batch2_epoch100_modelresnet34-imagenet\n",
      "\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.9117\n",
      "Average IoU: 0.2905\n",
      "Train Loss: 0.911653357744217, Train IOU: 0.29052696228028296\n",
      "Valid Loss: nan, Valid IOU: nan\n",
      "CheckPoint Save class-cypress_data28_batch2_epoch100_modelresnet34-imagenet\n",
      "\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.9117\n",
      "Average IoU: 0.2905\n",
      "Train Loss: 0.9116533815860748, Train IOU: 0.2905269622802782\n",
      "Valid Loss: nan, Valid IOU: nan\n",
      "CheckPoint Save class-cypress_data28_batch2_epoch100_modelresnet34-imagenet\n",
      "\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.9117\n",
      "Average IoU: 0.2905\n",
      "Train Loss: 0.9116533696651459, Train IOU: 0.2905269622802782\n",
      "Valid Loss: nan, Valid IOU: nan\n",
      "CheckPoint Save class-cypress_data28_batch2_epoch100_modelresnet34-imagenet\n",
      "\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.9117\n",
      "Average IoU: 0.2905\n",
      "Train Loss: 0.9116533815860748, Train IOU: 0.29052696228027824\n",
      "Valid Loss: nan, Valid IOU: nan\n",
      "CheckPoint Save class-cypress_data28_batch2_epoch100_modelresnet34-imagenet\n",
      "\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.9117\n",
      "Average IoU: 0.2905\n",
      "Train Loss: 0.9116533726453782, Train IOU: 0.29052696228027824\n",
      "Valid Loss: nan, Valid IOU: nan\n",
      "CheckPoint Save class-cypress_data28_batch2_epoch100_modelresnet34-imagenet\n",
      "\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.9117\n",
      "Average IoU: 0.2905\n",
      "Train Loss: 0.9116533875465394, Train IOU: 0.29052696228028296\n",
      "Valid Loss: nan, Valid IOU: nan\n",
      "CheckPoint Save class-cypress_data28_batch2_epoch100_modelresnet34-imagenet\n",
      "\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.9117\n",
      "Average IoU: 0.2905\n",
      "Train Loss: 0.9116533637046814, Train IOU: 0.2905269622802782\n",
      "Valid Loss: nan, Valid IOU: nan\n",
      "CheckPoint Save class-cypress_data28_batch2_epoch100_modelresnet34-imagenet\n",
      "\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.9117\n",
      "Average IoU: 0.2905\n",
      "Train Loss: 0.9116533517837524, Train IOU: 0.29052696228027824\n",
      "Valid Loss: nan, Valid IOU: nan\n",
      "CheckPoint Save class-cypress_data28_batch2_epoch100_modelresnet34-imagenet\n",
      "\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.9117\n",
      "Average IoU: 0.2905\n",
      "Train Loss: 0.91165332198143, Train IOU: 0.2905269622802877\n",
      "Valid Loss: nan, Valid IOU: nan\n",
      "CheckPoint Save class-cypress_data28_batch2_epoch100_modelresnet34-imagenet\n",
      "\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.9117\n",
      "Average IoU: 0.2905\n",
      "Train Loss: 0.911653333902359, Train IOU: 0.29052696228028296\n",
      "Valid Loss: nan, Valid IOU: nan\n",
      "CheckPoint Save class-cypress_data28_batch2_epoch100_modelresnet34-imagenet\n",
      "\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.9117\n",
      "Average IoU: 0.2905\n",
      "Train Loss: 0.9116533517837524, Train IOU: 0.2905269622802877\n",
      "Valid Loss: nan, Valid IOU: nan\n",
      "CheckPoint Save class-cypress_data28_batch2_epoch100_modelresnet34-imagenet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {str(epoch+1)}/{str(num_epochs)}\")\n",
    "\n",
    "#<---------------トレーニング---------------------->\n",
    "    train_loss = []\n",
    "    train_score = []\n",
    "    valid_loss = []\n",
    "    valid_score = []\n",
    "    train_loader_pbar = tqdm(train_loader, desc = 'description')\n",
    "    valid_loss_min = 0\n",
    "    \n",
    "    #<---------------評価---------------------->\n",
    "    losses_value, score = pre_segmentation_model.validateModel(model, train_loader_pbar, workDir=workDir,epoch=epoch,means=mean_values,stds=std_deviation, modelID=modelID)\n",
    "\n",
    "    train_loss.append(losses_value)\n",
    "    train_score.append(score)\n",
    "    \n",
    "    train_loader_pbar.set_description(f\"Epoch: {epoch+1}, loss: {losses_value}, IoU: {score}\")\n",
    "    \n",
    "    total_train_loss.append(np.mean(train_loss))\n",
    "    total_train_score.append(np.mean(train_score))\n",
    "    total_valid_loss.append(np.mean(valid_loss))\n",
    "    total_valid_score.append(np.mean(valid_score))\n",
    "    print(f\"Train Loss: {total_train_loss[-1]}, Train IOU: {total_train_score[-1]}\")\n",
    "    print(f\"Valid Loss: {total_valid_loss[-1]}, Valid IOU: {total_valid_score[-1]}\")\n",
    "\n",
    "    \n",
    "    checkpoint = {\n",
    "        'epoch': epoch + 1,\n",
    "        'valid_loss_min': total_valid_loss[-1],\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }\n",
    "    \n",
    "    print(\"CheckPoint Save\",modelID)\n",
    "\n",
    "    # checkpointの保存\n",
    "    save_ckp(checkpoint, False, checkpoint_path, best_model_path)\n",
    "    \n",
    "    # 評価データにおいて最高精度のモデルのcheckpointの保存\n",
    "    if total_valid_loss[-1] <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,total_valid_loss[-1]))\n",
    "        save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n",
    "        valid_loss_min = total_valid_loss[-1]\n",
    "    \n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "    score = {\n",
    "        # \"epoch\" : range(1,num_epochs+1),\n",
    "        \"train_Loss\" : total_train_loss,\n",
    "        \"valid__Loss\" : total_valid_loss,\n",
    "        \"train_scoreIoU\" : total_train_score,\n",
    "        \"valid__scoreIoU\" : total_valid_score,\n",
    "        }\n",
    "\n",
    "    import pandas as pd\n",
    "    df_score = pd.DataFrame(score, index=range(1,len(total_train_loss)+1))\n",
    "    df_score.to_csv(workDir + f\"scoreSheet_{modelID}.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1615e1",
   "metadata": {
    "id": "1b1615e1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab4ab5d-0b15-4fa5-ba6d-00f38998ee9d",
   "metadata": {
    "id": "aab4ab5d-0b15-4fa5-ba6d-00f38998ee9d"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
